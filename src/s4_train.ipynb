{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "''' This script does:\n",
    "1. Load features and labels from csv files\n",
    "2. Train the model\n",
    "3. Save the model to `model/` folder.\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "if True:  # Include project path\n",
    "    import sys\n",
    "    import os\n",
    "    ROOT = os.path.dirname(os.path.abspath(__file__))+\"/../\"\n",
    "    CURR_PATH = os.path.dirname(os.path.abspath(__file__))+\"/\"\n",
    "    sys.path.append(ROOT)\n",
    "\n",
    "    import utils.lib_plot as lib_plot\n",
    "    import utils.lib_commons as lib_commons\n",
    "    from utils.lib_classifier import ClassifierOfflineTrain\n",
    "\n",
    "\n",
    "\n",
    "def par(path):  # Pre-Append ROOT to the path if it's not absolute\n",
    "    return ROOT + path if (path and path[0] != \"/\") else path\n",
    "\n",
    "# -- Settings\n",
    "\n",
    "\n",
    "cfg_all = lib_commons.read_yaml(ROOT + \"config/config.yaml\")\n",
    "cfg = cfg_all[\"s4_train.py\"]\n",
    "\n",
    "CLASSES = np.array(cfg_all[\"classes\"])\n",
    "\n",
    "\n",
    "SRC_PROCESSED_FEATURES = par(cfg[\"input\"][\"processed_features\"])\n",
    "SRC_PROCESSED_FEATURES_LABELS = par(cfg[\"input\"][\"processed_features_labels\"])\n",
    "\n",
    "DST_MODEL_PATH = par(cfg[\"output\"][\"model_path\"])\n",
    "\n",
    "# -- Functions\n",
    "\n",
    "def train_test_split(X, Y, ratio_of_test_size):\n",
    "    ''' Split training data by ratio '''\n",
    "    IS_SPLIT_BY_SKLEARN_FUNC = True\n",
    "\n",
    "    # Use sklearn.train_test_split\n",
    "    if IS_SPLIT_BY_SKLEARN_FUNC:\n",
    "        RAND_SEED = 1\n",
    "        tr_X, te_X, tr_Y, te_Y = sklearn.model_selection.train_test_split(\n",
    "            X, Y, test_size=ratio_of_test_size, random_state=RAND_SEED)\n",
    "\n",
    "    # Make train/test the same.\n",
    "    else:\n",
    "        tr_X = np.copy(X)\n",
    "        tr_Y = Y.copy()\n",
    "        te_X = np.copy(X)\n",
    "        te_Y = Y.copy()\n",
    "    return tr_X, te_X, tr_Y, te_Y\n",
    "\n",
    "def evaluate_model(model, classes, tr_X, tr_Y, te_X, te_Y):\n",
    "    ''' Evaluate accuracy and time cost '''\n",
    "\n",
    "    # Accuracy\n",
    "    t0 = time.time()\n",
    "\n",
    "    tr_accu, tr_Y_predict = model.predict_and_evaluate(tr_X, tr_Y)\n",
    "    print(f\"Accuracy on training set is {tr_accu}\")\n",
    "\n",
    "    te_accu, te_Y_predict = model.predict_and_evaluate(te_X, te_Y)\n",
    "    print(f\"Accuracy on testing set is {te_accu}\")\n",
    "\n",
    "    print(\"Accuracy report:\")\n",
    "    print(classification_report(\n",
    "        te_Y, te_Y_predict, target_names=classes, output_dict=False))\n",
    "\n",
    "    # Time cost\n",
    "    average_time = (time.time() - t0) / (len(tr_Y) + len(te_Y))\n",
    "    print(\"Time cost for predicting one sample: \"\n",
    "          \"{:.5f} seconds\".format(average_time))\n",
    "\n",
    "    # Plot accuracy\n",
    "    axis, cf = lib_plot.plot_confusion_matrix(\n",
    "        te_Y, te_Y_predict, classes, normalize=False, size=(12, 8))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# -- Main\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # -- Load preprocessed data\n",
    "    print(\"\\nReading csv files of classes, features, and labels ...\")\n",
    "    X = np.loadtxt(SRC_PROCESSED_FEATURES, dtype=float)  # features\n",
    "    Y = np.loadtxt(SRC_PROCESSED_FEATURES_LABELS, dtype=int)  # labels\n",
    "    \n",
    "    # -- Train-test split\n",
    "    tr_X, te_X, tr_Y, te_Y = train_test_split(\n",
    "        X, Y, ratio_of_test_size=0.3)\n",
    "    print(\"\\nAfter train-test split:\")\n",
    "    print(\"Size of training data X:    \", tr_X.shape)\n",
    "    print(\"Number of training samples: \", len(tr_Y))\n",
    "    print(\"Number of testing samples:  \", len(te_Y))\n",
    "\n",
    "    # -- Train the model\n",
    "    print(\"\\nStart training model ...\")\n",
    "    model = ClassifierOfflineTrain()\n",
    "    model.train(tr_X, tr_Y)\n",
    "\n",
    "    # -- Evaluate model\n",
    "    print(\"\\nStart evaluating model ...\")\n",
    "    evaluate_model(model, CLASSES, tr_X, tr_Y, te_X, te_Y)\n",
    "\n",
    "    # -- Save model\n",
    "    print(\"\\nSave model to \" + DST_MODEL_PATH)\n",
    "    with open(DST_MODEL_PATH, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}