{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "'''\n",
    "Read multiple skeletons txts and saved them into a single txt.\n",
    "If an image doesn't have skeleton, discard it.\n",
    "If an image label is not `CLASSES`, discard it.\n",
    "\n",
    "Input:\n",
    "    `skeletons/00001.txt` ~ `skeletons/xxxxx.txt` from `SRC_DETECTED_SKELETONS_FOLDER`.\n",
    "Output:\n",
    "    `skeletons_info.txt`. The filepath is `DST_ALL_SKELETONS_TXT`.\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import simplejson\n",
    "import collections\n",
    "\n",
    "if True:  # Include project path\n",
    "    import sys\n",
    "    import os\n",
    "    ROOT = os.path.dirname(os.path.abspath(__file__))+\"/../\"\n",
    "    CURR_PATH = os.path.dirname(os.path.abspath(__file__))+\"/\"\n",
    "    sys.path.append(ROOT)\n",
    "\n",
    "    # import utils.lib_feature_proc # This is no needed,\n",
    "    #   because this script only transfer (part of) the data from many txts to a single txt,\n",
    "    #   without doing any data analsysis.\n",
    "\n",
    "    import utils.lib_commons as lib_commons\n",
    "\n",
    "\n",
    "def par(path):  # Pre-Append ROOT to the path if it's not absolute\n",
    "    return ROOT + path if (path and path[0] != \"/\") else path\n",
    "\n",
    "# -- Settings\n",
    "\n",
    "\n",
    "cfg_all = lib_commons.read_yaml(ROOT + \"config/config.yaml\")\n",
    "cfg = cfg_all[\"s2_put_skeleton_txts_to_a_single_txt.py\"]\n",
    "\n",
    "CLASSES = np.array(cfg_all[\"classes\"])\n",
    "\n",
    "SKELETON_FILENAME_FORMAT = cfg_all[\"skeleton_filename_format\"]\n",
    "\n",
    "SRC_DETECTED_SKELETONS_FOLDER = par(cfg[\"input\"][\"detected_skeletons_folder\"])\n",
    "DST_ALL_SKELETONS_TXT = par(cfg[\"output\"][\"all_skeletons_txt\"])\n",
    "\n",
    "IDX_PERSON = 0  # Only use the skeleton of the 0th person in each image\n",
    "IDX_ACTION_LABEL = 3  # [1, 7, 54, \"jump\", \"jump_03-02-12-34-01-795/00240.jpg\"]\n",
    "\n",
    "# -- Helper function\n",
    "\n",
    "\n",
    "def read_skeletons_from_ith_txt(i):\n",
    "    ''' \n",
    "    Arguments:\n",
    "        i {int}: the ith skeleton txt. Zero-based index.\n",
    "            If there are mutliple people, then there are multiple skeletons' data in this txt.\n",
    "    Return:\n",
    "        skeletons_in_ith_txt {list of list}:\n",
    "            Length of each skeleton data is supposed to be 41 = 5 image info + 36 xy positions. \n",
    "    '''\n",
    "    filename = SRC_DETECTED_SKELETONS_FOLDER + \\\n",
    "        SKELETON_FILENAME_FORMAT.format(i)\n",
    "    skeletons_in_ith_txt = lib_commons.read_listlist(filename)\n",
    "    return skeletons_in_ith_txt\n",
    "\n",
    "\n",
    "def get_length_of_one_skeleton_data(filepaths):\n",
    "    ''' Find a non-empty txt file, and then get the length of one skeleton data.\n",
    "    The data length should be 41, where:\n",
    "    41 = 5 + 36.\n",
    "        5: [cnt_action, cnt_clip, cnt_image, action_label, filepath]\n",
    "            See utils.lib_io.get_training_imgs_info for more details\n",
    "        36: 18 joints * 2 xy positions\n",
    "    '''\n",
    "    for i in range(len(filepaths)):\n",
    "        skeletons = read_skeletons_from_ith_txt(i)\n",
    "        if len(skeletons):\n",
    "            skeleton = skeletons[IDX_PERSON]\n",
    "            data_size = len(skeleton)\n",
    "            assert(data_size == 41)\n",
    "            return data_size\n",
    "    raise RuntimeError(f\"No valid txt under: {SRC_DETECTED_SKELETONS_FOLDER}.\")\n",
    "\n",
    "\n",
    "# -- Main\n",
    "if __name__ == \"__main__\":\n",
    "    ''' Read multiple skeletons txts and saved them into a single txt. '''\n",
    "\n",
    "    # -- Get skeleton filenames\n",
    "    filepaths = lib_commons.get_filenames(SRC_DETECTED_SKELETONS_FOLDER,\n",
    "                                          use_sort=True, with_folder_path=True)\n",
    "    num_skeletons = len(filepaths)\n",
    "\n",
    "    # -- Check data length of one skeleton\n",
    "    data_length = get_length_of_one_skeleton_data(filepaths)\n",
    "    print(\"Data length of one skeleton is {data_length}\")\n",
    "\n",
    "    # -- Read in skeletons and push to all_skeletons\n",
    "    all_skeletons = []\n",
    "    labels_cnt = collections.defaultdict(int)\n",
    "    for i in range(num_skeletons):\n",
    "\n",
    "        # Read skeletons from a txt\n",
    "        skeletons = read_skeletons_from_ith_txt(i)\n",
    "        if not skeletons:  # If empty, discard this image.\n",
    "            continue\n",
    "        skeleton = skeletons[IDX_PERSON]\n",
    "        label = skeleton[IDX_ACTION_LABEL]\n",
    "        if label not in CLASSES:  # If invalid label, discard this image.\n",
    "            continue\n",
    "        labels_cnt[label] += 1\n",
    "\n",
    "        # Push to result\n",
    "        all_skeletons.append(skeleton)\n",
    "\n",
    "        # Print\n",
    "        if i == 1 or i % 100 == 0:\n",
    "            print(\"{}/{}\".format(i, num_skeletons))\n",
    "\n",
    "    # -- Save to txt\n",
    "    with open(DST_ALL_SKELETONS_TXT, 'w') as f:\n",
    "        simplejson.dump(all_skeletons, f)\n",
    "\n",
    "    print(f\"There are {len(all_skeletons)} skeleton data.\")\n",
    "    print(f\"They are saved to {DST_ALL_SKELETONS_TXT}\")\n",
    "    print(\"Number of each action: \")\n",
    "    for label in CLASSES:\n",
    "        print(f\"    {label}: {labels_cnt[label]}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}